{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR-10 Batch size",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR09QNIuzdrH"
      },
      "source": [
        "# Maximum batch size to fit the GPU\n",
        "\n",
        "It is a common practice to use the largest batch size that fits the GPU memory for training. This example code shows how to automatically determine the largest batch size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVYOkez1s5X_"
      },
      "source": [
        "!pip install labml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4gdp8uW3uUj"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNCLoSMyroGJ"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from labml import lab, tracker, experiment, monit, logger\n",
        "from labml.logger import Text"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8rEwG1p3vyN"
      },
      "source": [
        "VGG Net for CIFAR-10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPOGCcQ_syXL"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        layers = []\n",
        "        in_channels = 3\n",
        "        for block in [[64, 64], [128, 128], [256, 256, 256], [512, 512, 512], [512, 512, 512]]:\n",
        "            for channels in block:\n",
        "                layers += [nn.Conv2d(in_channels, channels, kernel_size=3, padding=1),\n",
        "                           nn.BatchNorm2d(channels),\n",
        "                           nn.ReLU(inplace=True)]\n",
        "                in_channels = channels\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "        self.fc = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layers(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        return self.fc(x)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frGXX4FQ33LP"
      },
      "source": [
        "### Create data loaders with a given batch size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQQpT6vpyD_g"
      },
      "source": [
        "class DataLoaderFactory:\n",
        "    def __init__(self):\n",
        "        data_transform =  transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "\n",
        "        self.dataset = [\n",
        "                        datasets.CIFAR10(str(lab.get_data_path()),\n",
        "                            train=False,\n",
        "                            download=True,\n",
        "                            transform=data_transform),\n",
        "                        datasets.CIFAR10(str(lab.get_data_path()),\n",
        "                            train=True,\n",
        "                            download=True,\n",
        "                            transform=data_transform),\n",
        "        ]\n",
        "     \n",
        "    def __call__(self, train, batch_size):\n",
        "        return torch.utils.data.DataLoader(self.dataset[train],\n",
        "                                           batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2k3J7CZ39mm"
      },
      "source": [
        "### Determine if a given batch size can fit the GPU memory.\n",
        "\n",
        "It runs the model with the given batch size and does an optimization step. If the GPU runs out of memory it will crash with a `RuntimeError('CUDA out of memory.')`. We check for this and detemine if the batch size is too large.\n",
        "Note that we do `torch.cuda.empty_cache()` at the beginning to make sure all the caches (from previous tries) are cleared before we try to allocate new memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uVhuB6t0PiS"
      },
      "source": [
        "def check_batch_size(model, optimizer, batch_size):\n",
        "    data_loader = dl_factory(True, batch_size)\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    try:\n",
        "        data, target = next(iter(data_loader))\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        logger.log(f\"batch_size: {batch_size}\", Text.success)\n",
        "        return True\n",
        "    except RuntimeError as e:\n",
        "        if len(e.args) != 1:\n",
        "            raise e\n",
        "        msg: str = e.args[0]\n",
        "        if not isinstance(msg, str):\n",
        "            raise e\n",
        "        if not msg.startswith('CUDA out of memory.'):\n",
        "            raise e\n",
        "        logger.log(f\"batch_size: {batch_size}\", Text.danger)\n",
        "        return False"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWDn517u4v5m"
      },
      "source": [
        "### Find the largest batch size\n",
        "\n",
        "Run a simple binary search to find the highest possible batch size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0x65rbmIw_JE"
      },
      "source": [
        "def find_batch_size(dl_factory, device, max_bs = 2 ** 14):\n",
        "    model = Net().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "    model.train()\n",
        "\n",
        "    hi = max_bs\n",
        "    lo = 0\n",
        "\n",
        "    while lo < hi:\n",
        "        m = (hi + lo + 1) // 2\n",
        "\n",
        "        if check_batch_size(model, optimizer, m):\n",
        "            lo = m\n",
        "        else:\n",
        "            hi = m - 1\n",
        "\n",
        "    return lo"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0Zr7E035FEQ"
      },
      "source": [
        "Train the model for an epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_4ACTp4tFvQ"
      },
      "source": [
        "def train(model, optimizer, train_loader, device):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in monit.enum(\"Train\", train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        tracker.add_global_step(data.shape[0])\n",
        "        tracker.save({'loss.train': loss})"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3FW48QS5HOs"
      },
      "source": [
        "Get model validation loss and accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmX0C2m8tLbk"
      },
      "source": [
        "def validate(model, valid_loader, device):\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in monit.iterate(\"valid\", valid_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            output = model(data)\n",
        "            valid_loss += F.cross_entropy(output, target,\n",
        "                                          reduction='sum').item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    valid_loss /= len(valid_loader.dataset)\n",
        "    valid_accuracy = 100. * correct / len(valid_loader.dataset)\n",
        "\n",
        "    tracker.save({'loss.valid': valid_loss, 'accuracy.valid': valid_accuracy})"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4bYFTUE5M17"
      },
      "source": [
        "Configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF_o7VFltSDw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5f164eb-50ee-41a8-820a-437d6c3daed4"
      },
      "source": [
        "configs = {\n",
        "    'epochs': 50,\n",
        "    'learning_rate': 2.5e-4,\n",
        "    'device': \"cuda:0\" if torch.cuda.is_available() else \"cpu\",\n",
        "}\n",
        "\n",
        "device = torch.device(configs['device'])\n",
        "dl_factory = DataLoaderFactory()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TJ88ADh5Y_Y"
      },
      "source": [
        "Find optimal batch size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "Iykg93gn5XAz",
        "outputId": "971f1b73-c44b-4c6a-97ec-5cb0be04ddcc"
      },
      "source": [
        "batch_size = find_batch_size(dl_factory, device)\n",
        "batch_size"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"overflow-x: scroll;\"><span style=\"color: #E75C58\">batch_size: 8192</span>\n",
              "<span style=\"color: #00A250\">batch_size: 4096</span>\n",
              "<span style=\"color: #E75C58\">batch_size: 6144</span>\n",
              "<span style=\"color: #00A250\">batch_size: 5120</span>\n",
              "<span style=\"color: #E75C58\">batch_size: 5632</span>\n",
              "<span style=\"color: #00A250\">batch_size: 5376</span>\n",
              "<span style=\"color: #E75C58\">batch_size: 5504</span>\n",
              "<span style=\"color: #E75C58\">batch_size: 5440</span>\n",
              "<span style=\"color: #00A250\">batch_size: 5408</span>\n",
              "<span style=\"color: #00A250\">batch_size: 5424</span>\n",
              "<span style=\"color: #E75C58\">batch_size: 5432</span>\n",
              "<span style=\"color: #E75C58\">batch_size: 5428</span>\n",
              "<span style=\"color: #E75C58\">batch_size: 5426</span>\n",
              "<span style=\"color: #E75C58\">batch_size: 5425</span></pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5424"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjKX5FH75oKe"
      },
      "source": [
        "Create data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IDa3F-M5cj6"
      },
      "source": [
        "configs['batch_size'] = batch_size\n",
        "train_loader = dl_factory(True, batch_size)\n",
        "valid_loader = dl_factory(False, batch_size)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqDTccdV5puU"
      },
      "source": [
        "Create the model and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYrImlEQ5hL6"
      },
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=configs['learning_rate'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ceLIf3_5rZV"
      },
      "source": [
        "Run the training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        },
        "id": "YJ0MvOlb5lY-",
        "outputId": "5a604010-8b86-4168-b86b-d43354e28b42"
      },
      "source": [
        "experiment.create(name='cifar10')\n",
        "experiment.configs(configs)\n",
        "\n",
        "with experiment.start():\n",
        "    for _ in monit.loop(range(1, configs['epochs'] + 1)):\n",
        "        torch.cuda.empty_cache()\n",
        "        train(model, optimizer, train_loader, device)\n",
        "        validate(model, valid_loader, device)\n",
        "        logger.log()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"overflow-x: scroll;\">\n",
              "\n",
              "<strong><span style=\"text-decoration: underline\">cifar10</span></strong>: <span style=\"color: #208FFB\">3bcb6c469e9211eb9a5d0242ac1c0002</span>\n",
              "\t[dirty]: <strong><span style=\"color: #DDB62B\">\"\"</span></strong>\n",
              "<span style=\"color: #C5C1B4\"></span>\n",
              "<span style=\"color: #C5C1B4\">--------------------------------------------------</span><span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\"></span></strong></span>\n",
              "<span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\">LABML WARNING</span></strong></span>\n",
              "<span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\"></span></strong></span>LabML App Warning: <span style=\"color: #60C6C8\">empty_token: </span><strong>Please create a valid token at https://app.labml.ai.</strong>\n",
              "<strong>Click on the experiment link to monitor the experiment and add it to your experiments list.</strong><span style=\"color: #C5C1B4\"></span>\n",
              "<span style=\"color: #C5C1B4\">--------------------------------------------------</span>\n",
              "<span style=\"color: #208FFB\">Monitor experiment at </span><a href='https://app.labml.ai/run/3bcb6c469e9211eb9a5d0242ac1c0002' target='blank'>https://app.labml.ai/run/3bcb6c469e9211eb9a5d0242ac1c0002</a>\n",
              "<strong><span style=\"color: #DDB62B\">  50,001:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 52,573ms  </span>valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 1,521ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.54652</span> loss.valid: <strong> 2.32795</strong> accuracy.valid: <strong>10.00000</strong>  <span style=\"color: #208FFB\">54,094ms</span><span style=\"color: #D160C4\">  0:00m/  0:44m  </span>\n",
              "<strong><span style=\"color: #DDB62B\"> 100,001:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 53,432ms  </span>valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 2,077ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.28539</span> loss.valid: <strong> 2.51851</strong> accuracy.valid: <strong> 10.7900</strong>  <span style=\"color: #208FFB\">53,208ms</span><span style=\"color: #D160C4\">  0:01m/  0:42m  </span>\n",
              "<strong><span style=\"color: #DDB62B\"> 150,001:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 54,315ms  </span>valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 2,340ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 1.09932</span> loss.valid: <strong> 2.39539</strong> accuracy.valid: <strong> 20.6600</strong>  <span style=\"color: #208FFB\">53,083ms</span><span style=\"color: #D160C4\">  0:02m/  0:41m  </span>\n",
              "<strong><span style=\"color: #DDB62B\"> 200,001:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 54,904ms  </span>valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 2,544ms  </span> loss.train: <span style=\"color: #C5C1B4\"> 0.94300</span> loss.valid: <strong> 1.68287</strong> accuracy.valid: <strong> 36.7200</strong>  <span style=\"color: #208FFB\">53,368ms</span><span style=\"color: #D160C4\">  0:03m/  0:40m  </span>\n",
              "<strong><span style=\"color: #DDB62B\"> 250,001:  </span></strong>Train:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 56,750ms  </span>valid:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\"> 2,650ms  </span> loss.train: <span style=\"color: #C5C1B4\">0.765919</span> loss.valid: <strong> 1.31663</strong> accuracy.valid: <strong> 51.2200</strong>  <span style=\"color: #208FFB\">53,723ms</span><span style=\"color: #D160C4\">  0:04m/  0:40m  </span>\n",
              "<strong><span style=\"color: #DDB62B\">Still updating app.labml.ai, please wait for it to complete...</span></strong>\n",
              "<span style=\"color: #208FFB\">Updating App. Please wait</span></pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-6a54c7a9d7b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmonit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-06dfdacf3d11>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, train_loader, device)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'loss.train'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/labml/tracker.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0m_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/labml/tracker.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tracker.add should be called as add(name, value), add(dictionary) or add(k=v,k2=v2...)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0m_add_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/labml/tracker.py\u001b[0m in \u001b[0;36m_add_dict\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_add_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0m_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/labml/internal/tracker/__init__.py\u001b[0m in \u001b[0;36mstore\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_indicator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindicators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnew_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/labml/internal/tracker/indicators/numeric.py\u001b[0m in \u001b[0;36mcollect_value\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcollect_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/labml/internal/util/values.py\u001b[0m in \u001b[0;36mto_numpy\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unknown type {type(value)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp6IdiO6tk3p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}