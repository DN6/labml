{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "MNIST PyTorch",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AYV_dMVDxyc2"
   },
   "source": [
    "[![Github](https://img.shields.io/github/stars/labmlai/labml?style=social)](https://github.com/labmlai/labml/tree/master/samples/pytorch/mnist)\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/labmlai/labml/blob/master/master/samples/pytorch/mnist/mnist.ipynb)\n",
    "\n",
    "## MNIST Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XNbK5kWpt4uk"
   },
   "source": [
    "### Install the labml"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RJZxpbUAt3E_",
    "outputId": "1c7e22f2-5379-4adc-dfb4-bb1d39d6776d"
   },
   "source": [
    "!pip install labml"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: labml in /usr/local/lib/python3.6/dist-packages (0.4.102)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from labml) (1.19.5)\n",
      "Requirement already satisfied: gitpython in /usr/local/lib/python3.6/dist-packages (from labml) (3.1.13)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from labml) (3.13)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from gitpython->labml) (4.0.5)\n",
      "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->gitpython->labml) (3.0.5)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i8Zmkb1qR9nY"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PRp5k8TwwAoo"
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from labml import lab, tracker, experiment"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JgAyptsbSovw"
   },
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7NDj0ekpwLdj"
   },
   "source": [
    "class Model(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.conv1 = nn.Conv2d(1, 20, 5, 1) # 28 * 28\n",
    "    self.pool1 = nn.MaxPool2d(2) # 24 * 24\n",
    "    self.conv2 = nn.Conv2d(20, 50, 5, 1) # 12 * 12\n",
    "    self.pool2 = nn.MaxPool2d(2) # 8 * 8\n",
    "\n",
    "    self.fc1 = nn.Linear(4 * 4 * 50, 500) # 4 * 4\n",
    "    self.fc2 = nn.Linear(500, 10)\n",
    "    self.activation = nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.activation(self.conv1(x))\n",
    "    x = self.pool1(x)\n",
    "    x = self.activation(self.conv2(x))\n",
    "    x = self.pool2(x)\n",
    "    x = x.view(-1, 4 * 4 * 50)\n",
    "    x = self.activation(self.fc1(x))\n",
    "    x = self.fc2(x)\n",
    "    return x"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ge16KOWQGe7I"
   },
   "source": [
    "### Training code\n",
    "\n",
    "This trains the model for one epoch.\n",
    "\n",
    "We increment the step by the number of samples processed.\n",
    "The loss is saved on every batch and the model stats are saved every `model_log_interval`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qYeXqUlHGe7I"
   },
   "source": [
    "def train(model, loss_func, optimizer, loader, device, model_log_interval):\n",
    "  model.train()\n",
    "\n",
    "  for i, (data, target) in enumerate(loader):\n",
    "    data, target = data.to(device), target.to(device)\n",
    "\n",
    "    output = model(data)\n",
    "    loss = loss_func(output, target)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # ✨ Increment the global step\n",
    "    tracker.add_global_step(len(data))\n",
    "    # ✨ Save stats\n",
    "    tracker.save({'loss.train': loss})\n",
    "\n",
    "    if (i + 1) % model_log_interval == 0:\n",
    "        # ✨ Save model stats\n",
    "        tracker.save(model=model)"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WT5J5gz0Ge7J"
   },
   "source": [
    "### Validation code\n",
    "\n",
    "This evaluates the model on validation dataset, and save the stats at the end."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "G1Um3iSyGe7J"
   },
   "source": [
    "def validate(model, loss_func, loader, device):\n",
    "  model.eval()\n",
    "\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in loader:\n",
    "      data, target = data.to(device), target.to(device)\n",
    "\n",
    "      output = model(data)\n",
    "      tracker.add('loss.valid', loss_func(output, target))\n",
    "\n",
    "      pred = output.argmax(dim=1, keepdim=True)\n",
    "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "  \n",
    "  valid_accuracy = 100. * correct / len(valid_loader.dataset)\n",
    "\n",
    "  # **✨ Save stats**\n",
    "  tracker.save({'accuracy.valid': valid_accuracy})"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzmttM2mlA54"
   },
   "source": [
    "### \\[Optional\\] Setup tracker indicators\n",
    "\n",
    "This tells the tracker to:\n",
    "* use a queue of length 20 for training loss,\n",
    "* save the validation losses as a histogram,\n",
    "* save the validation accuracy as a scalar,\n",
    "\n",
    "and print each of the metrics to the terminal."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2P4pSklOlJfh"
   },
   "source": [
    "# ✨ Set the types of the stats/indicators.\n",
    "# They default to scalars if not specified\n",
    "tracker.set_queue('loss.train', 20, True)\n",
    "tracker.set_histogram('loss.valid', True)\n",
    "tracker.set_scalar('accuracy.valid', True)"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNF-nrfllJzb"
   },
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "z-KsmBnDlQZN"
   },
   "source": [
    "configs = {\n",
    "    'epochs': 10,\n",
    "    'train_batch_size': 64,\n",
    "    'valid_batch_size': 100,\n",
    "    'use_cuda': True,\n",
    "    'seed': 5,\n",
    "    'train_log_interval': 10,\n",
    "    'learning_rate': 0.01,\n",
    "}"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MlZc2uhkTXSi"
   },
   "source": [
    "### Initialize"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-f0fEoBywQyu",
    "outputId": "3f1584af-9132-4dad-8f13-4b411079fe3b"
   },
   "source": [
    "is_cuda = configs['use_cuda'] and torch.cuda.is_available()\n",
    "if not is_cuda:\n",
    "    device = torch.device(\"cpu\")\n",
    "else:\n",
    "    device = torch.device(f\"cuda:0\")\n",
    "\n",
    "mnist_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "train_loader = DataLoader(datasets.MNIST(str(lab.get_data_path()), \n",
    "                                         train=True,\n",
    "                                         transform=mnist_transform, \n",
    "                                         download=True),\n",
    "                          batch_size=configs['train_batch_size'], shuffle=True)\n",
    "\n",
    "valid_loader = DataLoader(datasets.MNIST(str(lab.get_data_path()), \n",
    "                                         train=False, \n",
    "                                         download=True,\n",
    "                                         transform=mnist_transform),\n",
    "                          batch_size=configs['valid_batch_size'], shuffle=False)\n",
    "\n",
    "model = Model().to(device)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=configs['learning_rate'])\n",
    "torch.manual_seed(configs['seed'])"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7e50c5ebd0>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 8
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmFwaMfPGe7L"
   },
   "source": [
    "### Run the experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38seNekBGe7L"
   },
   "source": [
    "Create the experiment"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dzoFv6GyGe7L"
   },
   "source": [
    "experiment.create(name='mnist_pytorch')"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deRTdZYdGe7L"
   },
   "source": [
    "Save experiment configurations/hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HaAwmSnIGe7L",
    "outputId": "c64681db-dda5-4740-daac-3dccd9304728",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    }
   },
   "source": [
    "experiment.configs(configs)"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"overflow-x: scroll;\"></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     }
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHtpMmleGe7M"
   },
   "source": [
    "Set PyTorch models for checkpoint saving and loading"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0uLFqgopGe7N"
   },
   "source": [
    "experiment.add_pytorch_models(dict(model=model))"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kenlTRcOGe7N"
   },
   "source": [
    "Run the experiment"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9bFbbz6eGe7N",
    "outputId": "d2b9399f-cfae-4de6-de52-0096062a40b6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    }
   },
   "source": [
    "with experiment.start():\n",
    "  for epoch in range(1, configs['epochs'] + 1):\n",
    "    train(model, loss_func, optimizer, train_loader, device, configs['train_log_interval'])\n",
    "    validate(model, loss_func, valid_loader, device)\n",
    "    tracker.new_line()\n",
    "\n",
    "    # ✨ Save the models\n",
    "    experiment.save_checkpoint()"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<pre style=\"overflow-x: scroll;\">\n",
       "<strong><span style=\"text-decoration: underline\">mnist_pytorch</span></strong>: <span style=\"color: #208FFB\">baa210086cdb11eb861b0242ac1c0002</span>\n",
       "\t[dirty]: <strong><span style=\"color: #DDB62B\">\"\"</span></strong>\n",
       "<span style=\"color: #C5C1B4\"></span>\n",
       "<span style=\"color: #C5C1B4\">--------------------------------------------------</span><span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\"></span></strong></span>\n",
       "<span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\">LABML WARNING</span></strong></span>\n",
       "<span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\"></span></strong></span>LabML App Warning: <span style=\"color: #60C6C8\">empty_token: </span><strong>Please create a valid token at https://web.lab-ml.com.</strong>\n",
       "<strong>Click on the experiment link to monitor the experiment and add it to your experiments list.</strong><span style=\"color: #C5C1B4\"></span>\n",
       "<span style=\"color: #C5C1B4\">--------------------------------------------------</span>\n",
       "<span style=\"color: #208FFB\">Monitor experiment at </span><a href='https://web.lab-ml.com/run?uuid=baa210086cdb11eb861b0242ac1c0002' target='blank'>https://web.lab-ml.com/run?uuid=baa210086cdb11eb861b0242ac1c0002</a>\n",
       "<strong><span style=\"color: #DDB62B\">  60,000:  </span></strong> loss.train: <span style=\"color: #C5C1B4\">0.179426</span> loss.valid: <strong>0.160103</strong> accuracy.valid: <strong> 95.1500</strong>\n",
       "<strong><span style=\"color: #DDB62B\"> 120,000:  </span></strong> loss.train: <span style=\"color: #C5C1B4\">0.096715</span> loss.valid: <strong>0.101894</strong> accuracy.valid: <strong> 97.1200</strong>\n",
       "<strong><span style=\"color: #DDB62B\"> 180,000:  </span></strong> loss.train: <span style=\"color: #C5C1B4\">0.076783</span> loss.valid: <strong>0.080147</strong> accuracy.valid: <strong> 97.5700</strong>\n",
       "<strong><span style=\"color: #DDB62B\"> 240,000:  </span></strong> loss.train: <span style=\"color: #C5C1B4\">0.055275</span> loss.valid: <strong>0.057459</strong> accuracy.valid: <strong> 98.3100</strong>\n",
       "<strong><span style=\"color: #DDB62B\"> 300,000:  </span></strong> loss.train: <span style=\"color: #C5C1B4\">0.068738</span> loss.valid: <strong>0.054456</strong> accuracy.valid: <strong> 98.3600</strong>\n",
       "<strong><span style=\"color: #DDB62B\"> 360,000:  </span></strong> loss.train: <span style=\"color: #C5C1B4\">0.054038</span> loss.valid: <strong>0.043333</strong> accuracy.valid: <strong> 98.6100</strong>\n",
       "<strong><span style=\"color: #DDB62B\"> 420,000:  </span></strong> loss.train: <span style=\"color: #C5C1B4\">0.060097</span> loss.valid: <strong>0.042030</strong> accuracy.valid: <strong> 98.6800</strong>\n",
       "<strong><span style=\"color: #DDB62B\"> 480,000:  </span></strong> loss.train: <span style=\"color: #C5C1B4\">0.042645</span> loss.valid: <strong>0.038582</strong> accuracy.valid: <strong> 98.6700</strong>\n",
       "<strong><span style=\"color: #DDB62B\"> 540,000:  </span></strong> loss.train: <span style=\"color: #C5C1B4\">0.048330</span> loss.valid: <strong>0.038091</strong> accuracy.valid: <strong> 98.6500</strong>\n",
       "<strong><span style=\"color: #DDB62B\"> 600,000:  </span></strong> loss.train: <span style=\"color: #C5C1B4\">0.042532</span> loss.valid: <strong>0.040111</strong> accuracy.valid: <strong> 98.6300</strong>\n",
       "<strong><span style=\"color: #DDB62B\">Still updating LabML App, please wait for it to complete...</span></strong></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     }
    }
   ]
  }
 ]
}